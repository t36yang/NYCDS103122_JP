{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Multiple-Linear-Regression\" data-toc-modified-id=\"Multiple-Linear-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Multiple Linear Regression</a></span></li><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Regression-with-Multiple-Predictors\" data-toc-modified-id=\"Regression-with-Multiple-Predictors-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regression with Multiple Predictors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Expanding-Simple-Linear-Regression\" data-toc-modified-id=\"Expanding-Simple-Linear-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Expanding Simple Linear Regression</a></span></li><li><span><a href=\"#Closed-form-Solution\" data-toc-modified-id=\"Closed-form-Solution-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Closed-form Solution</a></span></li></ul></li><li><span><a href=\"#Confounding-Variables\" data-toc-modified-id=\"Confounding-Variables-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Confounding Variables</a></span></li><li><span><a href=\"#Dealing-with-Categorical-Variables\" data-toc-modified-id=\"Dealing-with-Categorical-Variables-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Dealing with Categorical Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dummying\" data-toc-modified-id=\"Dummying-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dummying</a></span></li></ul></li><li><span><a href=\"#Multiple-Regression-in-statsmodels\" data-toc-modified-id=\"Multiple-Regression-in-statsmodels-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Multiple Regression in <code>statsmodels</code></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Diamonds-Dataset\" data-toc-modified-id=\"Diamonds-Dataset-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Diamonds Dataset</a></span></li><li><span><a href=\"#Check-distribution-of-target\" data-toc-modified-id=\"Check-distribution-of-target-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Check distribution of target</a></span></li><li><span><a href=\"#Build-model-with-log-scaled-target\" data-toc-modified-id=\"Build-model-with-log-scaled-target-6.0.3\"><span class=\"toc-item-num\">6.0.3&nbsp;&nbsp;</span>Build model with log-scaled target</a></span></li></ul></li></ul></li><li><span><a href=\"#Putting-it-in-Practice:-Wine-Dataset-üç∑\" data-toc-modified-id=\"Putting-it-in-Practice:-Wine-Dataset-üç∑-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Putting it in Practice: Wine Dataset üç∑</a></span><ul class=\"toc-item\"><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span></li><li><span><a href=\"#Running-the-Regression\" data-toc-modified-id=\"Running-the-Regression-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Running the Regression</a></span></li></ul></li><li><span><a href=\"#Scaling---The-Missing-&amp;-Helpful-Step\" data-toc-modified-id=\"Scaling---The-Missing-&amp;-Helpful-Step-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Scaling - The Missing &amp; Helpful Step</a></span><ul class=\"toc-item\"><li><span><a href=\"#What's-Going-on-Here?\" data-toc-modified-id=\"What's-Going-on-Here?-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>What's Going on Here?</a></span></li><li><span><a href=\"#A-Solution:-Standard-Scaling\" data-toc-modified-id=\"A-Solution:-Standard-Scaling-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>A Solution: Standard Scaling</a></span></li><li><span><a href=\"#Redoing-with-Standard-Scaling\" data-toc-modified-id=\"Redoing-with-Standard-Scaling-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Redoing with Standard Scaling</a></span></li><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span></li><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Follow-Up\" data-toc-modified-id=\"Follow-Up-8.5.1\"><span class=\"toc-item-num\">8.5.1&nbsp;&nbsp;</span>Follow-Up</a></span></li></ul></li></ul></li><li><span><a href=\"#Multiple-Regression-in-Scikit-Learn\" data-toc-modified-id=\"Multiple-Regression-in-Scikit-Learn-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Multiple Regression in Scikit-Learn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scale-the-Data\" data-toc-modified-id=\"Scale-the-Data-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Scale the Data</a></span></li><li><span><a href=\"#Fit-the-Model\" data-toc-modified-id=\"Fit-the-Model-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Fit the Model</a></span></li><li><span><a href=\"#Evaluate-Performance\" data-toc-modified-id=\"Evaluate-Performance-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Evaluate Performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Observing-Residuals\" data-toc-modified-id=\"Observing-Residuals-9.3.1\"><span class=\"toc-item-num\">9.3.1&nbsp;&nbsp;</span>Observing Residuals</a></span></li><li><span><a href=\"#Sklearn-Metrics\" data-toc-modified-id=\"Sklearn-Metrics-9.3.2\"><span class=\"toc-item-num\">9.3.2&nbsp;&nbsp;</span>Sklearn Metrics</a></span></li><li><span><a href=\"#More-in-Exploring-of-the-Predictions\" data-toc-modified-id=\"More-in-Exploring-of-the-Predictions-9.3.3\"><span class=\"toc-item-num\">9.3.3&nbsp;&nbsp;</span>More in Exploring of the Predictions</a></span></li></ul></li></ul></li><li><span><a href=\"#Level-Up:-Deeper-Evaluation-of-Wine-Data-Predictions\" data-toc-modified-id=\"Level-Up:-Deeper-Evaluation-of-Wine-Data-Predictions-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Level Up: Deeper Evaluation of Wine Data Predictions</a></span></li><li><span><a href=\"#Level-Up:-Regression-with-Categorical-Features-with-the-Comma-Dataset\" data-toc-modified-id=\"Level-Up:-Regression-with-Categorical-Features-with-the-Comma-Dataset-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Level Up: Regression with Categorical Features with the Comma Dataset</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "from random import gauss\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mlr](https://miro.medium.com/max/1280/1*lJKFo3yyZaFIx4ET1dLmlg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Use the one-hot strategy to encode categorical variables\n",
    "- Conduct linear regressions in `statsmodels`\n",
    "- Use standard scaling for linear regression for better  interpretation\n",
    "- Conduct linear regressions in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Regression with Multiple Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> It's all a bunch of dials\n",
    "\n",
    "<img width='450px' src='img/dials.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The main idea here is pretty simple. Whereas, in simple linear regression we took our dependent variable to be a function only of a single independent variable, here we'll be taking the dependent variable to be a function of multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Expanding Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our regression equation, then, instead of looking like $\\hat{y} = mx + b$, will now look like:\n",
    "\n",
    "$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + ... + \\hat{\\beta}_nx_n$.\n",
    "\n",
    "Remember that the hats ( $\\hat{}$ ) indicate parameters that are estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is this still a best-fit *line*? Well, no. What does the graph of, say, z = x + y look like? [Here's](https://academo.org/demos/3d-surface-plotter/) a 3d-plotter. (Of course, once we get x's with subscripts beyond 2 it's going to be very hard to visualize. But in practice linear regressions can make use of dozens or even of hundreds of independent variables!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Closed-form Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is it possible to calculate the betas by hand? Yes, a multiple regression problem still has a closed-form solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a word, for a multiple linear regression problem where $X$ is the matrix of independent variable values and $y$ is the vector of dependent variable values, the vector of optimizing regression coefficients $\\vec{b}$ is given by:\n",
    "\n",
    "$\\vec{b} = (X^TX)^{-1}X^Ty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll focus more directly on matrix mathematics later in the course, so don't worry if this equation is opaque to you. See [here](https://stattrek.com/multiple-regression/regression-coefficients.aspx) for a nice explanation and example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Confounding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose I have a simple linear regression that models the growth of corn plants as a function of the temperature of the ambient air. And suppose there is a noticeable positive correlation between temperature and plant height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corn = pd.read_csv('data/corn.csv',\n",
    "                  usecols=['temp', 'humid', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(data=corn, x='temp', y='height')\n",
    "plt.xlabel('Temperature ($\\degree$ F)')\n",
    "plt.ylabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of temperature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humid</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.086965</td>\n",
       "      <td>49.848304</td>\n",
       "      <td>122.222368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.582087</td>\n",
       "      <td>22.855446</td>\n",
       "      <td>110.079666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.868571</td>\n",
       "      <td>72.856834</td>\n",
       "      <td>256.812528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.732376</td>\n",
       "      <td>38.907566</td>\n",
       "      <td>167.889601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.384666</td>\n",
       "      <td>42.570524</td>\n",
       "      <td>188.914312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temp      humid      height\n",
       "0  58.086965  49.848304  122.222368\n",
       "1  70.582087  22.855446  110.079666\n",
       "2  75.868571  72.856834  256.812528\n",
       "3  74.732376  38.907566  167.889601\n",
       "4  77.384666  42.570524  188.914312"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corn.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It seems that higher temperatures lead to taller corn plants. But it's hard to know for sure. One **confounding variable** might be *humidity*. If we haven't controlled for humidity, then it's difficult to draw conclusions.\n",
    "\n",
    "One solution is to use **both features** in a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(data=corn, x='humid', y='height')\n",
    "plt.xlabel('Humidity (%)')\n",
    "plt.ylabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of humidity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8, 6)).add_subplot(111, projection='3d')\n",
    "ax.scatter(corn['temp'], corn['humid'], corn['height'],\n",
    "           depthshade=True, s=40, color='#ff0000')\n",
    "# create x,y\n",
    "xx, yy = np.meshgrid(corn['temp'], corn['humid'])\n",
    "\n",
    "# calculate corresponding z\n",
    "z = 4.3825 * xx + 2.4693 * yy - 255.5434\n",
    "\n",
    "# plot the surface\n",
    "ax.plot_surface(xx, yy, z, alpha=0.01, color='#00ff00')\n",
    "\n",
    "ax.view_init(30, azim=240)\n",
    "ax.set_xlabel('Temperature ($\\degree$ F)')\n",
    "ax.set_ylabel('Humidity (%)')\n",
    "ax.set_zlabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of temperature and humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One risk we run when adding more predictors to a model is that their correlations with the target may be nearly *collinear* with each other. This can make it difficult to determine which predictor is doing the heavy lifting. We shall explore this theme of **multicollinearity** in more depth in due course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dealing with Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One issue we'd like to resolve is what to do with categorical variables, i.e. variables that represent categories rather than continua. In a Pandas DataFrame, these columns may well have strings or objects for values, but they need not. A certain heart-disease dataset from Kaggle, for example, has a target variable that takes values 0-4, each representing a different stage of heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Dummying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One very effective way of dealing with categorical variables is to dummy them out. What this involves is making a new column for _each categorical value in the column we're dummying out_.\n",
    "\n",
    "These new columns will be filled only with 0's and 1's, a 1 representing the presence of the relevant categorical value.\n",
    "\n",
    "Let's look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comma_use = pd.read_csv('data/comma-survey.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For more on this dataset see [here](https://fivethirtyeight.com/features/elitist-superfluous-or-popular-we-polled-americans-on-the-oxford-comma/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RespondentID</th>\n",
       "      <th>In your opinion, which sentence is more gramatically correct?</th>\n",
       "      <th>Prior to reading about it above, had you heard of the serial (or Oxford) comma?</th>\n",
       "      <th>How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?</th>\n",
       "      <th>How would you write the following sentence?</th>\n",
       "      <th>When faced with using the word \"data\", have you ever spent time considering if the word was a singular or plural noun?</th>\n",
       "      <th>How much, if at all, do you care about the debate over the use of the word \"data\" as a singluar or plural noun?</th>\n",
       "      <th>In your opinion, how important or unimportant is proper use of grammar?</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Household Income</th>\n",
       "      <th>Education</th>\n",
       "      <th>Location (Census Region)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3292953864</td>\n",
       "      <td>It's important for a person to be honest, kind...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>Some experts say it's important to drink milk,...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not much</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-44</td>\n",
       "      <td>$50,000 - $99,999</td>\n",
       "      <td>Bachelor degree</td>\n",
       "      <td>South Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3292950324</td>\n",
       "      <td>It's important for a person to be honest, kind...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not much</td>\n",
       "      <td>Some experts say it's important to drink milk,...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not much</td>\n",
       "      <td>Somewhat unimportant</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-44</td>\n",
       "      <td>$50,000 - $99,999</td>\n",
       "      <td>Graduate degree</td>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3292942669</td>\n",
       "      <td>It's important for a person to be honest, kind...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>Some experts say it's important to drink milk,...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>Very important</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East North Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3292932796</td>\n",
       "      <td>It's important for a person to be honest, kind...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>Some experts say it's important to drink milk,...</td>\n",
       "      <td>No</td>\n",
       "      <td>Some</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>Male</td>\n",
       "      <td>18-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than high school degree</td>\n",
       "      <td>Middle Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3292932522</td>\n",
       "      <td>It's important for a person to be honest, kind...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not much</td>\n",
       "      <td>Some experts say it's important to drink milk,...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not much</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RespondentID In your opinion, which sentence is more gramatically correct?  \\\n",
       "0    3292953864  It's important for a person to be honest, kind...              \n",
       "1    3292950324  It's important for a person to be honest, kind...              \n",
       "2    3292942669  It's important for a person to be honest, kind...              \n",
       "3    3292932796  It's important for a person to be honest, kind...              \n",
       "4    3292932522  It's important for a person to be honest, kind...              \n",
       "\n",
       "  Prior to reading about it above, had you heard of the serial (or Oxford) comma?  \\\n",
       "0                                                Yes                                \n",
       "1                                                 No                                \n",
       "2                                                Yes                                \n",
       "3                                                Yes                                \n",
       "4                                                 No                                \n",
       "\n",
       "  How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?  \\\n",
       "0                                               Some                                                             \n",
       "1                                           Not much                                                             \n",
       "2                                               Some                                                             \n",
       "3                                               Some                                                             \n",
       "4                                           Not much                                                             \n",
       "\n",
       "         How would you write the following sentence?  \\\n",
       "0  Some experts say it's important to drink milk,...   \n",
       "1  Some experts say it's important to drink milk,...   \n",
       "2  Some experts say it's important to drink milk,...   \n",
       "3  Some experts say it's important to drink milk,...   \n",
       "4  Some experts say it's important to drink milk,...   \n",
       "\n",
       "  When faced with using the word \"data\", have you ever spent time considering if the word was a singular or plural noun?  \\\n",
       "0                                                 No                                                                       \n",
       "1                                                 No                                                                       \n",
       "2                                                Yes                                                                       \n",
       "3                                                 No                                                                       \n",
       "4                                                 No                                                                       \n",
       "\n",
       "  How much, if at all, do you care about the debate over the use of the word \"data\" as a singluar or plural noun?  \\\n",
       "0                                           Not much                                                                \n",
       "1                                           Not much                                                                \n",
       "2                                         Not at all                                                                \n",
       "3                                               Some                                                                \n",
       "4                                           Not much                                                                \n",
       "\n",
       "  In your opinion, how important or unimportant is proper use of grammar?  \\\n",
       "0                                 Somewhat important                        \n",
       "1                               Somewhat unimportant                        \n",
       "2                                     Very important                        \n",
       "3                                 Somewhat important                        \n",
       "4                                                NaN                        \n",
       "\n",
       "  Gender    Age   Household Income                     Education  \\\n",
       "0   Male  30-44  $50,000 - $99,999               Bachelor degree   \n",
       "1   Male  30-44  $50,000 - $99,999               Graduate degree   \n",
       "2   Male  30-44                NaN                           NaN   \n",
       "3   Male  18-29                NaN  Less than high school degree   \n",
       "4    NaN    NaN                NaN                           NaN   \n",
       "\n",
       "  Location (Census Region)  \n",
       "0           South Atlantic  \n",
       "1                 Mountain  \n",
       "2       East North Central  \n",
       "3          Middle Atlantic  \n",
       "4                      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It's important for a person to be honest, kind, and loyal.    641\n",
       "It's important for a person to be honest, kind and loyal.     488\n",
       "Name: In your opinion, which sentence is more gramatically correct?, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_use['In your opinion, which sentence is more gramatically correct?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1129, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_use.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comma_use.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(825, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's try using sklearn's OneHotEncoder to create our dummy columns:\n",
    "\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "comma_trans = ohe.fit_transform(comma_use.drop('RespondentID', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Could we have used ```pd.get_dummies()``` instead?\n",
    "\n",
    "Well, yes. And in fact ```get_dummies()``` is in some ways easier; for one thing, it's built right into Pandas. But there are drawbacks with it as well. The main advantage of the `sklearn` tool is that it stores information about the columns and creates a persistent function that can be used on future data of the same form. See [this page](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In your opinion, which sentence is more gramatically correct?_It's important for a person to be honest, kind and loyal.</th>\n",
       "      <th>In your opinion, which sentence is more gramatically correct?_It's important for a person to be honest, kind, and loyal.</th>\n",
       "      <th>Prior to reading about it above, had you heard of the serial (or Oxford) comma?_No</th>\n",
       "      <th>Prior to reading about it above, had you heard of the serial (or Oxford) comma?_Yes</th>\n",
       "      <th>How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_A lot</th>\n",
       "      <th>How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_Not at all</th>\n",
       "      <th>How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_Not much</th>\n",
       "      <th>How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_Some</th>\n",
       "      <th>How would you write the following sentence?_Some experts say it's important to drink milk, but the data are inconclusive.</th>\n",
       "      <th>How would you write the following sentence?_Some experts say it's important to drink milk, but the data is inconclusive.</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Some college or Associate degree</th>\n",
       "      <th>Location (Census Region)_East North Central</th>\n",
       "      <th>Location (Census Region)_East South Central</th>\n",
       "      <th>Location (Census Region)_Middle Atlantic</th>\n",
       "      <th>Location (Census Region)_Mountain</th>\n",
       "      <th>Location (Census Region)_New England</th>\n",
       "      <th>Location (Census Region)_Pacific</th>\n",
       "      <th>Location (Census Region)_South Atlantic</th>\n",
       "      <th>Location (Census Region)_West North Central</th>\n",
       "      <th>Location (Census Region)_West South Central</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>825 rows √ó 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      In your opinion, which sentence is more gramatically correct?_It's important for a person to be honest, kind and loyal.  \\\n",
       "0                                                     1                                                                         \n",
       "1                                                     0                                                                         \n",
       "5                                                     0                                                                         \n",
       "6                                                     0                                                                         \n",
       "7                                                     0                                                                         \n",
       "...                                                 ...                                                                         \n",
       "1124                                                  0                                                                         \n",
       "1125                                                  1                                                                         \n",
       "1126                                                  0                                                                         \n",
       "1127                                                  1                                                                         \n",
       "1128                                                  1                                                                         \n",
       "\n",
       "      In your opinion, which sentence is more gramatically correct?_It's important for a person to be honest, kind, and loyal.  \\\n",
       "0                                                     0                                                                          \n",
       "1                                                     1                                                                          \n",
       "5                                                     1                                                                          \n",
       "6                                                     1                                                                          \n",
       "7                                                     1                                                                          \n",
       "...                                                 ...                                                                          \n",
       "1124                                                  1                                                                          \n",
       "1125                                                  0                                                                          \n",
       "1126                                                  1                                                                          \n",
       "1127                                                  0                                                                          \n",
       "1128                                                  0                                                                          \n",
       "\n",
       "      Prior to reading about it above, had you heard of the serial (or Oxford) comma?_No  \\\n",
       "0                                                     0                                    \n",
       "1                                                     1                                    \n",
       "5                                                     1                                    \n",
       "6                                                     0                                    \n",
       "7                                                     0                                    \n",
       "...                                                 ...                                    \n",
       "1124                                                  0                                    \n",
       "1125                                                  1                                    \n",
       "1126                                                  0                                    \n",
       "1127                                                  0                                    \n",
       "1128                                                  0                                    \n",
       "\n",
       "      Prior to reading about it above, had you heard of the serial (or Oxford) comma?_Yes  \\\n",
       "0                                                     1                                     \n",
       "1                                                     0                                     \n",
       "5                                                     0                                     \n",
       "6                                                     1                                     \n",
       "7                                                     1                                     \n",
       "...                                                 ...                                     \n",
       "1124                                                  1                                     \n",
       "1125                                                  0                                     \n",
       "1126                                                  1                                     \n",
       "1127                                                  1                                     \n",
       "1128                                                  1                                     \n",
       "\n",
       "      How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_A lot  \\\n",
       "0                                                     0                                                                    \n",
       "1                                                     0                                                                    \n",
       "5                                                     1                                                                    \n",
       "6                                                     1                                                                    \n",
       "7                                                     1                                                                    \n",
       "...                                                 ...                                                                    \n",
       "1124                                                  1                                                                    \n",
       "1125                                                  0                                                                    \n",
       "1126                                                  0                                                                    \n",
       "1127                                                  1                                                                    \n",
       "1128                                                  1                                                                    \n",
       "\n",
       "      How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_Not at all  \\\n",
       "0                                                     0                                                                         \n",
       "1                                                     0                                                                         \n",
       "5                                                     0                                                                         \n",
       "6                                                     0                                                                         \n",
       "7                                                     0                                                                         \n",
       "...                                                 ...                                                                         \n",
       "1124                                                  0                                                                         \n",
       "1125                                                  0                                                                         \n",
       "1126                                                  0                                                                         \n",
       "1127                                                  0                                                                         \n",
       "1128                                                  0                                                                         \n",
       "\n",
       "      How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_Not much  \\\n",
       "0                                                     0                                                                       \n",
       "1                                                     1                                                                       \n",
       "5                                                     0                                                                       \n",
       "6                                                     0                                                                       \n",
       "7                                                     0                                                                       \n",
       "...                                                 ...                                                                       \n",
       "1124                                                  0                                                                       \n",
       "1125                                                  0                                                                       \n",
       "1126                                                  0                                                                       \n",
       "1127                                                  0                                                                       \n",
       "1128                                                  0                                                                       \n",
       "\n",
       "      How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?_Some  \\\n",
       "0                                                     1                                                                   \n",
       "1                                                     0                                                                   \n",
       "5                                                     0                                                                   \n",
       "6                                                     0                                                                   \n",
       "7                                                     0                                                                   \n",
       "...                                                 ...                                                                   \n",
       "1124                                                  0                                                                   \n",
       "1125                                                  1                                                                   \n",
       "1126                                                  1                                                                   \n",
       "1127                                                  0                                                                   \n",
       "1128                                                  0                                                                   \n",
       "\n",
       "      How would you write the following sentence?_Some experts say it's important to drink milk, but the data are inconclusive.  \\\n",
       "0                                                     0                                                                           \n",
       "1                                                     0                                                                           \n",
       "5                                                     1                                                                           \n",
       "6                                                     0                                                                           \n",
       "7                                                     1                                                                           \n",
       "...                                                 ...                                                                           \n",
       "1124                                                  0                                                                           \n",
       "1125                                                  0                                                                           \n",
       "1126                                                  0                                                                           \n",
       "1127                                                  0                                                                           \n",
       "1128                                                  0                                                                           \n",
       "\n",
       "      How would you write the following sentence?_Some experts say it's important to drink milk, but the data is inconclusive.  \\\n",
       "0                                                     1                                                                          \n",
       "1                                                     1                                                                          \n",
       "5                                                     0                                                                          \n",
       "6                                                     1                                                                          \n",
       "7                                                     0                                                                          \n",
       "...                                                 ...                                                                          \n",
       "1124                                                  1                                                                          \n",
       "1125                                                  1                                                                          \n",
       "1126                                                  1                                                                          \n",
       "1127                                                  1                                                                          \n",
       "1128                                                  1                                                                          \n",
       "\n",
       "      ...  Education_Some college or Associate degree  \\\n",
       "0     ...                                           0   \n",
       "1     ...                                           0   \n",
       "5     ...                                           1   \n",
       "6     ...                                           1   \n",
       "7     ...                                           1   \n",
       "...   ...                                         ...   \n",
       "1124  ...                                           1   \n",
       "1125  ...                                           1   \n",
       "1126  ...                                           0   \n",
       "1127  ...                                           0   \n",
       "1128  ...                                           0   \n",
       "\n",
       "      Location (Census Region)_East North Central  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "5                                               0   \n",
       "6                                               0   \n",
       "7                                               1   \n",
       "...                                           ...   \n",
       "1124                                            0   \n",
       "1125                                            0   \n",
       "1126                                            0   \n",
       "1127                                            0   \n",
       "1128                                            0   \n",
       "\n",
       "      Location (Census Region)_East South Central  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "5                                               0   \n",
       "6                                               0   \n",
       "7                                               0   \n",
       "...                                           ...   \n",
       "1124                                            0   \n",
       "1125                                            0   \n",
       "1126                                            0   \n",
       "1127                                            1   \n",
       "1128                                            0   \n",
       "\n",
       "      Location (Census Region)_Middle Atlantic  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "5                                            0   \n",
       "6                                            0   \n",
       "7                                            0   \n",
       "...                                        ...   \n",
       "1124                                         0   \n",
       "1125                                         0   \n",
       "1126                                         1   \n",
       "1127                                         0   \n",
       "1128                                         0   \n",
       "\n",
       "      Location (Census Region)_Mountain  Location (Census Region)_New England  \\\n",
       "0                                     0                                     0   \n",
       "1                                     1                                     0   \n",
       "5                                     0                                     1   \n",
       "6                                     0                                     0   \n",
       "7                                     0                                     0   \n",
       "...                                 ...                                   ...   \n",
       "1124                                  0                                     0   \n",
       "1125                                  0                                     0   \n",
       "1126                                  0                                     0   \n",
       "1127                                  0                                     0   \n",
       "1128                                  1                                     0   \n",
       "\n",
       "      Location (Census Region)_Pacific  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "5                                    0   \n",
       "6                                    1   \n",
       "7                                    0   \n",
       "...                                ...   \n",
       "1124                                 0   \n",
       "1125                                 1   \n",
       "1126                                 0   \n",
       "1127                                 0   \n",
       "1128                                 0   \n",
       "\n",
       "      Location (Census Region)_South Atlantic  \\\n",
       "0                                           1   \n",
       "1                                           0   \n",
       "5                                           0   \n",
       "6                                           0   \n",
       "7                                           0   \n",
       "...                                       ...   \n",
       "1124                                        1   \n",
       "1125                                        0   \n",
       "1126                                        0   \n",
       "1127                                        0   \n",
       "1128                                        0   \n",
       "\n",
       "      Location (Census Region)_West North Central  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "5                                               0   \n",
       "6                                               0   \n",
       "7                                               0   \n",
       "...                                           ...   \n",
       "1124                                            0   \n",
       "1125                                            0   \n",
       "1126                                            0   \n",
       "1127                                            0   \n",
       "1128                                            0   \n",
       "\n",
       "      Location (Census Region)_West South Central  \n",
       "0                                               0  \n",
       "1                                               0  \n",
       "5                                               0  \n",
       "6                                               0  \n",
       "7                                               0  \n",
       "...                                           ...  \n",
       "1124                                            0  \n",
       "1125                                            0  \n",
       "1126                                            0  \n",
       "1127                                            0  \n",
       "1128                                            0  \n",
       "\n",
       "[825 rows x 46 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(comma_use.drop('RespondentID', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So what did the encoder do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<825x34 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7174 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., ..., 1., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_trans.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"x0_It's important for a person to be honest, kind, and loyal.\",\n",
       "       'x1_Yes', 'x2_Not at all', 'x2_Not much', 'x2_Some',\n",
       "       \"x3_Some experts say it's important to drink milk, but the data is inconclusive.\",\n",
       "       'x4_Yes', 'x5_Not at all', 'x5_Not much', 'x5_Some',\n",
       "       'x6_Somewhat important', 'x6_Somewhat unimportant',\n",
       "       'x6_Very important', 'x6_Very unimportant', 'x7_Male', 'x8_30-44',\n",
       "       'x8_45-60', 'x8_> 60', 'x9_$100,000 - $149,999', 'x9_$150,000+',\n",
       "       'x9_$25,000 - $49,999', 'x9_$50,000 - $99,999',\n",
       "       'x10_Graduate degree', 'x10_High school degree',\n",
       "       'x10_Less than high school degree',\n",
       "       'x10_Some college or Associate degree', 'x11_East South Central',\n",
       "       'x11_Middle Atlantic', 'x11_Mountain', 'x11_New England',\n",
       "       'x11_Pacific', 'x11_South Atlantic', 'x11_West North Central',\n",
       "       'x11_West South Central'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_It's important for a person to be honest, kind, and loyal.</th>\n",
       "      <th>x1_Yes</th>\n",
       "      <th>x2_Not at all</th>\n",
       "      <th>x2_Not much</th>\n",
       "      <th>x2_Some</th>\n",
       "      <th>x3_Some experts say it's important to drink milk, but the data is inconclusive.</th>\n",
       "      <th>x4_Yes</th>\n",
       "      <th>x5_Not at all</th>\n",
       "      <th>x5_Not much</th>\n",
       "      <th>x5_Some</th>\n",
       "      <th>...</th>\n",
       "      <th>x10_Less than high school degree</th>\n",
       "      <th>x10_Some college or Associate degree</th>\n",
       "      <th>x11_East South Central</th>\n",
       "      <th>x11_Middle Atlantic</th>\n",
       "      <th>x11_Mountain</th>\n",
       "      <th>x11_New England</th>\n",
       "      <th>x11_Pacific</th>\n",
       "      <th>x11_South Atlantic</th>\n",
       "      <th>x11_West North Central</th>\n",
       "      <th>x11_West South Central</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_It's important for a person to be honest, kind, and loyal.  x1_Yes  \\\n",
       "0                                                0.0                 1.0   \n",
       "1                                                1.0                 0.0   \n",
       "2                                                1.0                 0.0   \n",
       "3                                                1.0                 1.0   \n",
       "4                                                1.0                 1.0   \n",
       "\n",
       "   x2_Not at all  x2_Not much  x2_Some  \\\n",
       "0            0.0          0.0      1.0   \n",
       "1            0.0          1.0      0.0   \n",
       "2            0.0          0.0      0.0   \n",
       "3            0.0          0.0      0.0   \n",
       "4            0.0          0.0      0.0   \n",
       "\n",
       "   x3_Some experts say it's important to drink milk, but the data is inconclusive.  \\\n",
       "0                                                1.0                                 \n",
       "1                                                1.0                                 \n",
       "2                                                0.0                                 \n",
       "3                                                1.0                                 \n",
       "4                                                0.0                                 \n",
       "\n",
       "   x4_Yes  x5_Not at all  x5_Not much  x5_Some  ...  \\\n",
       "0     0.0            0.0          1.0      0.0  ...   \n",
       "1     0.0            0.0          1.0      0.0  ...   \n",
       "2     1.0            0.0          0.0      1.0  ...   \n",
       "3     1.0            0.0          0.0      1.0  ...   \n",
       "4     0.0            0.0          0.0      0.0  ...   \n",
       "\n",
       "   x10_Less than high school degree  x10_Some college or Associate degree  \\\n",
       "0                               0.0                                   0.0   \n",
       "1                               0.0                                   0.0   \n",
       "2                               0.0                                   1.0   \n",
       "3                               0.0                                   1.0   \n",
       "4                               0.0                                   1.0   \n",
       "\n",
       "   x11_East South Central  x11_Middle Atlantic  x11_Mountain  x11_New England  \\\n",
       "0                     0.0                  0.0           0.0              0.0   \n",
       "1                     0.0                  0.0           1.0              0.0   \n",
       "2                     0.0                  0.0           0.0              1.0   \n",
       "3                     0.0                  0.0           0.0              0.0   \n",
       "4                     0.0                  0.0           0.0              0.0   \n",
       "\n",
       "   x11_Pacific  x11_South Atlantic  x11_West North Central  \\\n",
       "0          0.0                 1.0                     0.0   \n",
       "1          0.0                 0.0                     0.0   \n",
       "2          0.0                 0.0                     0.0   \n",
       "3          1.0                 0.0                     0.0   \n",
       "4          0.0                 0.0                     0.0   \n",
       "\n",
       "   x11_West South Central  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_df = pd.DataFrame(comma_trans.todense(), columns=ohe.get_feature_names())\n",
    "comma_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiple Regression in `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's build a multiple regression with `statsmodels`. Let's start with a toy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "centers = np.arange(1, 6)\n",
    "preds = np.array([stats.norm(loc=center, scale=3).rvs(200) for center in centers]).T\n",
    "preds_df = pd.DataFrame(preds, columns=[f'var{center}' for center in centers])\n",
    "\n",
    "target = preds_df['var1'] + 2*preds_df['var2'] + 3*preds_df['var3']\\\n",
    "    + 4*preds_df['var4'] + 5*preds_df['var5']\n",
    "target_df = pd.DataFrame(target, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.198017</td>\n",
       "      <td>5.823142</td>\n",
       "      <td>4.988094</td>\n",
       "      <td>8.447288</td>\n",
       "      <td>4.759885</td>\n",
       "      <td>88.397161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.207792</td>\n",
       "      <td>3.490127</td>\n",
       "      <td>3.257752</td>\n",
       "      <td>5.999115</td>\n",
       "      <td>7.022849</td>\n",
       "      <td>79.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.206935</td>\n",
       "      <td>0.108243</td>\n",
       "      <td>-5.487818</td>\n",
       "      <td>4.421006</td>\n",
       "      <td>2.576267</td>\n",
       "      <td>14.111457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.145255</td>\n",
       "      <td>-0.390655</td>\n",
       "      <td>4.904027</td>\n",
       "      <td>5.091114</td>\n",
       "      <td>1.203119</td>\n",
       "      <td>40.165566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.645824</td>\n",
       "      <td>5.644498</td>\n",
       "      <td>0.341577</td>\n",
       "      <td>9.030431</td>\n",
       "      <td>7.201730</td>\n",
       "      <td>87.089925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1      var2      var3      var4      var5     target\n",
       "0  4.198017  5.823142  4.988094  8.447288  4.759885  88.397161\n",
       "1  3.207792  3.490127  3.257752  5.999115  7.022849  79.072008\n",
       "2 -0.206935  0.108243 -5.487818  4.421006  2.576267  14.111457\n",
       "3 -0.145255 -0.390655  4.904027  5.091114  1.203119  40.165566\n",
       "4  2.645824  5.644498  0.341577  9.030431  7.201730  87.089925"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([preds_df, target_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(endog=y, exog=X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Diamonds Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = sns.load_dataset('diamonds').drop(['cut', 'color', 'clarity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, y = data.drop('price', axis=1), data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2 = sm.OLS(y, X).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm.graphics.plot_regress_exog(model2, 'carat', fig=plt.figure(figsize=(12, 8)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Check distribution of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_scld = np.log(y)\n",
    "y_scld.hist(bins=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Build model with log-scaled target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model3 = sm.OLS(y_scld, X).fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sm.graphics.plot_regress_exog(model3, 'carat', fig=plt.figure(figsize=(12, 8)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Remember that $R^2$ can be negative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bad_pred = np.mean(y) * np.ones(len(y))\n",
    "worse_pred = (np.mean(y) + 1000) * np.ones(len(y))\n",
    "\n",
    "print(metrics.r2_score(y, bad_pred))\n",
    "print(metrics.r2_score(y, worse_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Putting it in Practice: Wine Dataset üç∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This dataset includes measurable attributes of different wines as well as their rated quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  red_wine  \n",
       "0      9.4        5         1  \n",
       "1      9.8        5         1  \n",
       "2      9.8        5         1  \n",
       "3      9.8        6         1  \n",
       "4      9.4        5         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('data/wine.csv')\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine we want to attempt to estimate the perceived quality of a wine using these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine['red_wine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Why are we using \"quality\" as the dependent variable (target)? Would it make sense for another feature to be the target instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Running the Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, we'll separate the data into our predictors (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  red_wine  \n",
       "0      9.4         1  \n",
       "1      9.8         1  \n",
       "2      9.8         1  \n",
       "3      9.8         1  \n",
       "4      9.4         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_preds = wine.drop('quality', axis=1)\n",
    "wine_target = wine['quality']\n",
    "wine_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can perform our (multiple) linear regression! Since we already used `statsmodels`, let's use that again to fit the model and then check the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0       1.0            7.4              0.70         0.00             1.9   \n",
       "1       1.0            7.8              0.88         0.00             2.6   \n",
       "2       1.0            7.8              0.76         0.04             2.3   \n",
       "3       1.0           11.2              0.28         0.56             1.9   \n",
       "4       1.0            7.4              0.70         0.00             1.9   \n",
       "...     ...            ...               ...          ...             ...   \n",
       "6492    1.0            6.2              0.21         0.29             1.6   \n",
       "6493    1.0            6.6              0.32         0.36             8.0   \n",
       "6494    1.0            6.5              0.24         0.19             1.2   \n",
       "6495    1.0            5.5              0.29         0.30             1.1   \n",
       "6496    1.0            6.0              0.21         0.38             0.8   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "1         0.098                 25.0                  67.0  0.99680  3.20   \n",
       "2         0.092                 15.0                  54.0  0.99700  3.26   \n",
       "3         0.075                 17.0                  60.0  0.99800  3.16   \n",
       "4         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "6492      0.039                 24.0                  92.0  0.99114  3.27   \n",
       "6493      0.047                 57.0                 168.0  0.99490  3.15   \n",
       "6494      0.041                 30.0                 111.0  0.99254  2.99   \n",
       "6495      0.022                 20.0                 110.0  0.98869  3.34   \n",
       "6496      0.020                 22.0                  98.0  0.98941  3.26   \n",
       "\n",
       "      sulphates  alcohol  red_wine  \n",
       "0          0.56      9.4         1  \n",
       "1          0.68      9.8         1  \n",
       "2          0.65      9.8         1  \n",
       "3          0.58      9.8         1  \n",
       "4          0.56      9.4         1  \n",
       "...         ...      ...       ...  \n",
       "6492       0.50     11.2         0  \n",
       "6493       0.46      9.6         0  \n",
       "6494       0.46      9.4         0  \n",
       "6495       0.38     12.8         0  \n",
       "6496       0.32     11.8         0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sm.add_constant() to add constant term/y-intercept\n",
    "predictors = sm.add_constant(wine_preds)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(wine_target, predictors).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> All right! So we fitted our model! Take a look at the summary and look if you can understand the different parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.297</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.295</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:18:42</td>     <th>  Log-Likelihood:    </th> <td> -7195.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6497</td>      <th>  AIC:               </th> <td>1.442e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6484</td>      <th>  BIC:               </th> <td>1.450e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  104.3904</td> <td>   14.105</td> <td>    7.401</td> <td> 0.000</td> <td>   76.741</td> <td>  132.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.0851</td> <td>    0.016</td> <td>    5.396</td> <td> 0.000</td> <td>    0.054</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.4924</td> <td>    0.081</td> <td>  -18.345</td> <td> 0.000</td> <td>   -1.652</td> <td>   -1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -0.0626</td> <td>    0.080</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.219</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0624</td> <td>    0.006</td> <td>   10.522</td> <td> 0.000</td> <td>    0.051</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.7573</td> <td>    0.334</td> <td>   -2.264</td> <td> 0.024</td> <td>   -1.413</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0049</td> <td>    0.001</td> <td>    6.443</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0014</td> <td>    0.000</td> <td>   -4.333</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> -103.9096</td> <td>   14.336</td> <td>   -7.248</td> <td> 0.000</td> <td> -132.013</td> <td>  -75.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.4988</td> <td>    0.091</td> <td>    5.506</td> <td> 0.000</td> <td>    0.321</td> <td>    0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.7217</td> <td>    0.076</td> <td>    9.466</td> <td> 0.000</td> <td>    0.572</td> <td>    0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.2227</td> <td>    0.018</td> <td>   12.320</td> <td> 0.000</td> <td>    0.187</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>red_wine</th>             <td>    0.3613</td> <td>    0.057</td> <td>    6.367</td> <td> 0.000</td> <td>    0.250</td> <td>    0.473</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>140.992</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 313.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.016</td>  <th>  Prob(JB):          </th> <td>6.59e-69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.077</td>  <th>  Cond. No.          </th> <td>2.96e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.96e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.297\n",
       "Model:                            OLS   Adj. R-squared:                  0.295\n",
       "Method:                 Least Squares   F-statistic:                     227.8\n",
       "Date:                Thu, 01 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        14:18:42   Log-Likelihood:                -7195.2\n",
       "No. Observations:                6497   AIC:                         1.442e+04\n",
       "Df Residuals:                    6484   BIC:                         1.450e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  104.3904     14.105      7.401      0.000      76.741     132.040\n",
       "fixed acidity            0.0851      0.016      5.396      0.000       0.054       0.116\n",
       "volatile acidity        -1.4924      0.081    -18.345      0.000      -1.652      -1.333\n",
       "citric acid             -0.0626      0.080     -0.786      0.432      -0.219       0.094\n",
       "residual sugar           0.0624      0.006     10.522      0.000       0.051       0.074\n",
       "chlorides               -0.7573      0.334     -2.264      0.024      -1.413      -0.102\n",
       "free sulfur dioxide      0.0049      0.001      6.443      0.000       0.003       0.006\n",
       "total sulfur dioxide    -0.0014      0.000     -4.333      0.000      -0.002      -0.001\n",
       "density               -103.9096     14.336     -7.248      0.000    -132.013     -75.806\n",
       "pH                       0.4988      0.091      5.506      0.000       0.321       0.676\n",
       "sulphates                0.7217      0.076      9.466      0.000       0.572       0.871\n",
       "alcohol                  0.2227      0.018     12.320      0.000       0.187       0.258\n",
       "red_wine                 0.3613      0.057      6.367      0.000       0.250       0.473\n",
       "==============================================================================\n",
       "Omnibus:                      140.992   Durbin-Watson:                   1.648\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              313.985\n",
       "Skew:                           0.016   Prob(JB):                     6.59e-69\n",
       "Kurtosis:                       4.077   Cond. No.                     2.96e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.96e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scaling - The Missing & Helpful Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When you looked at the summary after we did the linear regression, you might have noticed something interesting.\n",
    "\n",
    "Observing the coefficients, you might notice there are two relatively large coefficients and nearly rest are less than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## What's Going on Here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a word, it's useful to have all of our variables be on the same scale, so that the resulting coefficients are easier to interpret. If the scales of the variables are very different one from another, then some of the coefficients may end up on very large or very tiny scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This happens since the coefficients will effectively attempt to \"shrink\" or \"expand\" the features before factoring their importance to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](img/shrinkinator.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This can make it more difficult for interpretation and identifying coefficients with the most \"effect\" on the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For more on this, see [this post](https://stats.stackexchange.com/questions/32649/some-of-my-predictors-are-on-very-different-scales-do-i-need-to-transform-them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Solution: Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One solution is to *scale* our features. There are a few ways to do this but we'll focus on **standard scaling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we do **standard scaling**, we're really scaling it to be the features' respective $z$-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Benefits:\n",
    "\n",
    "- This tends to make values relatively small (mean value is at $0$ and one standard deviation $\\sigma$ from the mean is $1$).\n",
    "- Easier interpretation: larger coefficients tend to be more influential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next time, let's *scale* our columns as $z$-scores first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Redoing with Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try standard scaling the model with our wine dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We'll include all the columns for now.\n",
    "\n",
    "wine_preds_scaled = (wine_preds - np.mean(wine_preds)) / np.std(wine_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.849639e-16</td>\n",
       "      <td>1.049902e-16</td>\n",
       "      <td>2.187295e-17</td>\n",
       "      <td>3.499672e-17</td>\n",
       "      <td>3.499672e-17</td>\n",
       "      <td>-8.749179e-17</td>\n",
       "      <td>-6.999344e-17</td>\n",
       "      <td>-3.534668e-15</td>\n",
       "      <td>2.729744e-15</td>\n",
       "      <td>-5.424491e-16</td>\n",
       "      <td>9.361622e-16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.634589e+00</td>\n",
       "      <td>-1.577330e+00</td>\n",
       "      <td>-2.192833e+00</td>\n",
       "      <td>-1.018034e+00</td>\n",
       "      <td>-1.342639e+00</td>\n",
       "      <td>-1.663583e+00</td>\n",
       "      <td>-1.941780e+00</td>\n",
       "      <td>-2.530192e+00</td>\n",
       "      <td>-3.100615e+00</td>\n",
       "      <td>-2.091935e+00</td>\n",
       "      <td>-2.089350e+00</td>\n",
       "      <td>-0.571367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.289329e-01</td>\n",
       "      <td>-6.661613e-01</td>\n",
       "      <td>-4.723335e-01</td>\n",
       "      <td>-7.657978e-01</td>\n",
       "      <td>-5.147986e-01</td>\n",
       "      <td>-7.620742e-01</td>\n",
       "      <td>-6.855323e-01</td>\n",
       "      <td>-7.859527e-01</td>\n",
       "      <td>-6.748622e-01</td>\n",
       "      <td>-6.805919e-01</td>\n",
       "      <td>-8.316152e-01</td>\n",
       "      <td>-0.571367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.660892e-01</td>\n",
       "      <td>-3.016939e-01</td>\n",
       "      <td>-5.941375e-02</td>\n",
       "      <td>-5.135612e-01</td>\n",
       "      <td>-2.578826e-01</td>\n",
       "      <td>-8.594301e-02</td>\n",
       "      <td>3.990667e-02</td>\n",
       "      <td>6.448888e-02</td>\n",
       "      <td>-5.287424e-02</td>\n",
       "      <td>-1.429373e-01</td>\n",
       "      <td>-1.608231e-01</td>\n",
       "      <td>-0.571367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.738951e-01</td>\n",
       "      <td>3.664962e-01</td>\n",
       "      <td>4.911459e-01</td>\n",
       "      <td>5.584445e-01</td>\n",
       "      <td>2.559494e-01</td>\n",
       "      <td>5.901882e-01</td>\n",
       "      <td>7.122647e-01</td>\n",
       "      <td>7.648525e-01</td>\n",
       "      <td>6.313125e-01</td>\n",
       "      <td>4.619241e-01</td>\n",
       "      <td>6.776670e-01</td>\n",
       "      <td>-0.571367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.699425e+00</td>\n",
       "      <td>7.534354e+00</td>\n",
       "      <td>9.231281e+00</td>\n",
       "      <td>1.268682e+01</td>\n",
       "      <td>1.584219e+01</td>\n",
       "      <td>1.456357e+01</td>\n",
       "      <td>5.737257e+00</td>\n",
       "      <td>1.476879e+01</td>\n",
       "      <td>4.923029e+00</td>\n",
       "      <td>9.870879e+00</td>\n",
       "      <td>3.696231e+00</td>\n",
       "      <td>1.750190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity   citric acid  residual sugar  \\\n",
       "count   6.497000e+03      6.497000e+03  6.497000e+03    6.497000e+03   \n",
       "mean   -3.849639e-16      1.049902e-16  2.187295e-17    3.499672e-17   \n",
       "std     1.000077e+00      1.000077e+00  1.000077e+00    1.000077e+00   \n",
       "min    -2.634589e+00     -1.577330e+00 -2.192833e+00   -1.018034e+00   \n",
       "25%    -6.289329e-01     -6.661613e-01 -4.723335e-01   -7.657978e-01   \n",
       "50%    -1.660892e-01     -3.016939e-01 -5.941375e-02   -5.135612e-01   \n",
       "75%     3.738951e-01      3.664962e-01  4.911459e-01    5.584445e-01   \n",
       "max     6.699425e+00      7.534354e+00  9.231281e+00    1.268682e+01   \n",
       "\n",
       "          chlorides  free sulfur dioxide  total sulfur dioxide       density  \\\n",
       "count  6.497000e+03         6.497000e+03          6.497000e+03  6.497000e+03   \n",
       "mean   3.499672e-17        -8.749179e-17         -6.999344e-17 -3.534668e-15   \n",
       "std    1.000077e+00         1.000077e+00          1.000077e+00  1.000077e+00   \n",
       "min   -1.342639e+00        -1.663583e+00         -1.941780e+00 -2.530192e+00   \n",
       "25%   -5.147986e-01        -7.620742e-01         -6.855323e-01 -7.859527e-01   \n",
       "50%   -2.578826e-01        -8.594301e-02          3.990667e-02  6.448888e-02   \n",
       "75%    2.559494e-01         5.901882e-01          7.122647e-01  7.648525e-01   \n",
       "max    1.584219e+01         1.456357e+01          5.737257e+00  1.476879e+01   \n",
       "\n",
       "                 pH     sulphates       alcohol     red_wine  \n",
       "count  6.497000e+03  6.497000e+03  6.497000e+03  6497.000000  \n",
       "mean   2.729744e-15 -5.424491e-16  9.361622e-16     0.000000  \n",
       "std    1.000077e+00  1.000077e+00  1.000077e+00     1.000077  \n",
       "min   -3.100615e+00 -2.091935e+00 -2.089350e+00    -0.571367  \n",
       "25%   -6.748622e-01 -6.805919e-01 -8.316152e-01    -0.571367  \n",
       "50%   -5.287424e-02 -1.429373e-01 -1.608231e-01    -0.571367  \n",
       "75%    6.313125e-01  4.619241e-01  6.776670e-01    -0.571367  \n",
       "max    4.923029e+00  9.870879e+00  3.696231e+00     1.750190  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_preds_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.297</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.295</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:19</td>     <th>  Log-Likelihood:    </th> <td> -7195.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6497</td>      <th>  AIC:               </th> <td>1.442e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6484</td>      <th>  BIC:               </th> <td>1.450e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    5.8184</td> <td>    0.009</td> <td>  639.726</td> <td> 0.000</td> <td>    5.801</td> <td>    5.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.1103</td> <td>    0.020</td> <td>    5.396</td> <td> 0.000</td> <td>    0.070</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -0.2457</td> <td>    0.013</td> <td>  -18.345</td> <td> 0.000</td> <td>   -0.272</td> <td>   -0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -0.0091</td> <td>    0.012</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.032</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.2970</td> <td>    0.028</td> <td>   10.522</td> <td> 0.000</td> <td>    0.242</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.0265</td> <td>    0.012</td> <td>   -2.264</td> <td> 0.024</td> <td>   -0.049</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0876</td> <td>    0.014</td> <td>    6.443</td> <td> 0.000</td> <td>    0.061</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0793</td> <td>    0.018</td> <td>   -4.333</td> <td> 0.000</td> <td>   -0.115</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td>   -0.3116</td> <td>    0.043</td> <td>   -7.248</td> <td> 0.000</td> <td>   -0.396</td> <td>   -0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.0802</td> <td>    0.015</td> <td>    5.506</td> <td> 0.000</td> <td>    0.052</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.1074</td> <td>    0.011</td> <td>    9.466</td> <td> 0.000</td> <td>    0.085</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.2656</td> <td>    0.022</td> <td>   12.320</td> <td> 0.000</td> <td>    0.223</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>red_wine</th>             <td>    0.1556</td> <td>    0.024</td> <td>    6.367</td> <td> 0.000</td> <td>    0.108</td> <td>    0.204</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>140.992</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 313.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.016</td>  <th>  Prob(JB):          </th> <td>6.59e-69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.077</td>  <th>  Cond. No.          </th> <td>    12.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.297\n",
       "Model:                            OLS   Adj. R-squared:                  0.295\n",
       "Method:                 Least Squares   F-statistic:                     227.8\n",
       "Date:                Thu, 01 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        14:19:19   Log-Likelihood:                -7195.2\n",
       "No. Observations:                6497   AIC:                         1.442e+04\n",
       "Df Residuals:                    6484   BIC:                         1.450e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    5.8184      0.009    639.726      0.000       5.801       5.836\n",
       "fixed acidity            0.1103      0.020      5.396      0.000       0.070       0.150\n",
       "volatile acidity        -0.2457      0.013    -18.345      0.000      -0.272      -0.219\n",
       "citric acid             -0.0091      0.012     -0.786      0.432      -0.032       0.014\n",
       "residual sugar           0.2970      0.028     10.522      0.000       0.242       0.352\n",
       "chlorides               -0.0265      0.012     -2.264      0.024      -0.049      -0.004\n",
       "free sulfur dioxide      0.0876      0.014      6.443      0.000       0.061       0.114\n",
       "total sulfur dioxide    -0.0793      0.018     -4.333      0.000      -0.115      -0.043\n",
       "density                 -0.3116      0.043     -7.248      0.000      -0.396      -0.227\n",
       "pH                       0.0802      0.015      5.506      0.000       0.052       0.109\n",
       "sulphates                0.1074      0.011      9.466      0.000       0.085       0.130\n",
       "alcohol                  0.2656      0.022     12.320      0.000       0.223       0.308\n",
       "red_wine                 0.1556      0.024      6.367      0.000       0.108       0.204\n",
       "==============================================================================\n",
       "Omnibus:                      140.992   Durbin-Watson:                   1.648\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              313.985\n",
       "Skew:                           0.016   Prob(JB):                     6.59e-69\n",
       "Kurtosis:                       4.077   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = sm.add_constant(wine_preds_scaled)\n",
    "model = sm.OLS(wine_target, predictors).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Check how well this model did with the one before scaling. Does it perform any differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> After standard scaling, what would it mean when all the $x_i$ are all $0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Follow-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> What does this mean for the constant term $\\hat{\\beta}_0$? Could we check this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine_target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiple Regression in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> It's great that we tried out multiple linear regression with `statsmodels`; now let's try it with `sklearn`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's create a StandardScaler object to scale our data for us.\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now we'll apply it to our data by using the .fit() and .transform() methods.\n",
    "ss.fit(wine_preds)\n",
    "\n",
    "wine_preds_st_scaled = ss.transform(wine_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_preds_st_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check that the scaling worked about the same as when we did it by hand\n",
    "np.allclose(wine_preds_st_scaled, wine_preds_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine_preds_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine_preds_st_scaled[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can fit a `LinearRegression` object to our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now we can fit a LinearRegression object to our training data!\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(wine_preds_st_scaled, wine_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can use the .coef_ attribute to recover the results\n",
    "# of the regression.\n",
    "\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr.score(wine_preds_st_scaled, wine_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat = lr.predict(wine_preds_st_scaled)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All that's left is to evaluate our model to see how well it did!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Observing Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can check the residuals like we would for a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat = lr.predict(wine_preds_st_scaled)\n",
    "resid = (wine_target - y_hat)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=range(y_hat.shape[0]),y=resid, alpha=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sklearn Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The metrics module in sklearn has a number of metrics that we can use to measure the accuracy of our model, including the $R^2$ score, the mean absolute error and the mean squared error. Note that the default 'score' on our model object is the $R^2$ score. Let's go back to our wine dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's make sure this metric is properly calibrated. If we put simply $\\bar{y}$ as our prediction, then we should get an $R^2$ score of *0*. And if we predict, say, $\\bar{y} + 1$, then we should get a *negative* $R^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_quality = np.mean(wine_target)\n",
    "num = len(wine_target)\n",
    "\n",
    "metrics.r2_score(wine_target, avg_quality * np.ones(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(wine_target, (avg_quality + 1) * np.ones(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Deeper Evaluation of Wine Data Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One thing we could have investigated from our [model on the Wine Data](#Multiple-Regression-in-Scikit-Learn) is how our predictions $\\hat{y}$ match with the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(y_hat,kde=True,fill=False,stat='density',color='red')\n",
    "sns.histplot(wine_target,discrete=True,stat='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So there's a slight issue with our model; the linear regression believes the target values are on a continuum. We know that's not true from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An easy fix is to round the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_rounded = np.round(y_hat)\n",
    "np.unique(y_hat_rounded, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plotting the distribution is a lot more meaningful if we require targets to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(np.round(y_hat),fill=False,discrete=True,stat='density',color='red')\n",
    "sns.histplot(wine_target,discrete=True,alpha=0.3,stat='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that our $R^2$ metric will be worse. This makes sense since we found a \"line of best fit\" that predicts continuous values. \n",
    "\n",
    "If the better option was _integer_ predictions, it would have predicted that instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(wine_target, y_hat_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You must decide yourself if this is worth doing or if a different model makes more sense (we'll see more models in future lectures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Regression with Categorical Features with the Comma Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comma_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We'll try to predict the first column of df: the extent to which\n",
    "# the person accepts the sentence\n",
    "# without the Oxford comma as more grammatically correct.\n",
    "\n",
    "comma_target = comma_df['x0_It\\'s important for a person to be honest, kind, and loyal.']\n",
    "\n",
    "comma_predictors = comma_df[['x8_30-44',\n",
    "       'x8_45-60', 'x8_> 60', 'x9_$100,000 - $149,999',\n",
    "       'x9_$150,000+', 'x9_$25,000 - $49,999', 'x9_$50,000 - $99,999']]\n",
    "\n",
    "comma_lr = LinearRegression()\n",
    "\n",
    "comma_lr.fit(comma_predictors, comma_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comma_lr.score(comma_predictors, comma_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(wine_target, y_hat_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comma_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comma_df.corr()['x0_It\\'s important for a person to be honest, kind, and loyal.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For more on the interpretation of regression coefficients for categorical variables, see [Erin's repo](https://github.com/hoffm386/coefficients-of-dropped-categorical-variables)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
